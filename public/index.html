<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Perplexity Real Voice Agent</title>
  <style>
    * { margin: 0; padding: 0; box-sizing: border-box; }
    body {
      font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      min-height: 100vh;
      display: flex;
      justify-content: center;
      align-items: center;
      padding: 20px;
    }
    .container {
      background: white;
      border-radius: 20px;
      padding: 40px;
      box-shadow: 0 20px 60px rgba(0,0,0,0.3);
      max-width: 500px;
      width: 100%;
      text-align: center;
    }
    h1 {
      color: #667eea;
      margin-bottom: 10px;
      font-size: 2rem;
    }
    .subtitle {
      color: #666;
      margin-bottom: 30px;
      font-size: 0.9rem;
    }
    .mic-button {
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      border: none;
      border-radius: 50%;
      width: 120px;
      height: 120px;
      color: white;
      font-size: 1.2rem;
      cursor: pointer;
      margin: 20px 0;
      transition: all 0.3s ease;
      box-shadow: 0 10px 30px rgba(102, 126, 234, 0.4);
    }
    .mic-button:hover {
      transform: scale(1.1);
      box-shadow: 0 15px 40px rgba(102, 126, 234, 0.6);
    }
    .mic-button:active {
      transform: scale(0.95);
    }
    .mic-button.listening {
      animation: pulse 1.5s infinite;
      background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
    }
    @keyframes pulse {
      0%, 100% { transform: scale(1); }
      50% { transform: scale(1.1); }
    }
    .model-switch {
      margin: 20px 0;
      display: flex;
      justify-content: center;
      gap: 10px;
    }
    .model-btn {
      padding: 10px 20px;
      border: 2px solid #667eea;
      border-radius: 25px;
      background: white;
      color: #667eea;
      cursor: pointer;
      transition: all 0.3s;
    }
    .model-btn.active {
      background: #667eea;
      color: white;
    }
    #status {
      margin-top: 20px;
      padding: 15px;
      border-radius: 10px;
      background: #f5f5f5;
      color: #333;
      min-height: 50px;
    }
    .powered {
      margin-top: 15px;
      font-size: 0.8rem;
      color: #999;
    }
  </style>
</head>
<body>
  <div class="container">
    <h1>ðŸŽ¤ PERPLEXITY VOICE AGENT</h1>
    <p class="subtitle">Mic se bol â€“ AI sune â€“ Jawab de!</p>

    <button id="micBtn" class="mic-button">ðŸŽ¤ Start Mic</button>

    <div class="model-switch">
      <button class="model-btn active" data-model="perplexity">Perplexity Mode</button>
      <button class="model-btn" data-model="gemini">Gemini Mode</button>
    </div>

    <div id="status">Ready...</div>
    <div class="powered">âš¡ Powered by Perplexity AI</div>
  </div>

  <script>
    const micBtn = document.getElementById('micBtn');
    const status = document.getElementById('status');
    const modelBtns = document.querySelectorAll('.model-btn');
    let selectedModel = 'perplexity';
    let recognition = null;

    // Check browser support
    if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      recognition = new SpeechRecognition();
      recognition.continuous = false;
      recognition.lang = 'en-US';

      recognition.onstart = () => {
        micBtn.classList.add('listening');
        micBtn.textContent = 'ðŸŽ¤ Listening...';
        status.textContent = 'Speak now...';
      };

      recognition.onresult = async (event) => {
        const transcript = event.results[0][0].transcript;
        status.textContent = `You said: ${transcript}`;

        try {
          const response = await fetch('/speak', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ text: transcript, model: selectedModel })
          });

          const data = await response.json();

          if (data.error) {
            status.textContent = `Error: ${data.error}`;
          } else {
            status.textContent = `AI: ${data.reply}`;
            speak(data.reply);
          }
        } catch (err) {
          status.textContent = `Error: ${err.message}`;
        }
      };

      recognition.onerror = (event) => {
        status.textContent = `Error: ${event.error}`;
        micBtn.classList.remove('listening');
        micBtn.textContent = 'ðŸŽ¤ Start Mic';
      };

      recognition.onend = () => {
        micBtn.classList.remove('listening');
        micBtn.textContent = 'ðŸŽ¤ Start Mic';
      };
    } else {
      status.textContent = 'Speech recognition not supported';
    }

    micBtn.addEventListener('click', () => {
      if (recognition) {
        recognition.start();
      }
    });

    modelBtns.forEach(btn => {
      btn.addEventListener('click', () => {
        modelBtns.forEach(b => b.classList.remove('active'));
        btn.classList.add('active');
        selectedModel = btn.dataset.model;
        status.textContent = `Switched to ${selectedModel.toUpperCase()} mode`;
      });
    });

    function speak(text) {
      if ('speechSynthesis' in window) {
        const utterance = new SpeechSynthesisUtterance(text);
        utterance.rate = 1.0;
        utterance.pitch = 1.0;
        window.speechSynthesis.speak(utterance);
      }
    }
  </script>
</body>
</html>